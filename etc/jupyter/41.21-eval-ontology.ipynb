{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from tqdm.auto import tqdm\n",
    "from icecream import ic\n",
    "from import_casa import casa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = casa.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = pd.read_csv(data_dir/r\"annot_data\\annotated_data_bkup\\20210605\\aspect_tuples_20210605.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DistilTag import DistilTag\n",
    "tagger = DistilTag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "a[slice(0, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def ngrams(text, ng_map, wsize=(2, 4)):    \n",
    "    for w in range(wsize[0], wsize[1]+1):\n",
    "        seqs = [text[slice(c, None)] for c in range(w)]\n",
    "        w_iter = (\"\".join(toks) for toks in zip(*seqs))\n",
    "        ng_map.setdefault(w, Counter()).update(w_iter)\n",
    "    return ng_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: Counter({'刷牙': 2, '牙刷': 1, '牙齒': 1}),\n",
       " 3: Counter({'刷牙刷': 1, '牙刷牙': 1, '刷牙齒': 1}),\n",
       " 4: Counter({'刷牙刷牙': 1, '牙刷牙齒': 1})}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_map = {}\n",
    "ngrams(\"刷牙刷牙齒\", ng_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight ngram frequency\n",
    "The reweighted score of ngram, $n$, is recursively defined as,\n",
    "$$\n",
    "score(n) = \\begin{cases}\n",
    "0, & f(n) = 1 \\\\\n",
    "\\max\\left(0, f(n) - \\sum_{m\\in H(n)} score(m)\\right), & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "where $f(n)$ is raw ngram frequency of $n$, and H(n) denotes all other ngrams containing $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(ng, ngfreq, scores, r=0):        \n",
    "    f_ng = ngfreq[ng] \n",
    "    # if r == 0: ic(r, ng, f_ng)\n",
    "    if f_ng == 1:\n",
    "        scores[ng] = 0                \n",
    "    else:\n",
    "        H = [x for x in ngfreq \n",
    "             if (ng in x) and (ng != x)]\n",
    "        scores[ng] = f_ng\n",
    "        for m in H:\n",
    "            scores[ng] -= compute_score(m, ngfreq, scores, r+1)    \n",
    "            # if r== 0: ic(m, scores[m])\n",
    "    scores[ng] = max(scores[ng], 0)\n",
    "    #if r==0: ic(r, ng, scores[ng])\n",
    "    return scores[ng]\n",
    "\n",
    "def compute_ngram_scores(ng_dict):\n",
    "    wsize = sorted(ng_dict.keys())\n",
    "    ngfreq = {k: freq for k, freq \n",
    "              in chain((*(ng_dict[w].items() for w in wsize)))}\n",
    "    buf = list(ngfreq.keys())\n",
    "    scores = {}\n",
    "    while buf:\n",
    "        ng = buf.pop()    \n",
    "        if ng in scores:\n",
    "            continue\n",
    "        else:        \n",
    "            scores[ng] = compute_score(ng, ngfreq, scores)\n",
    "    scores = {k: v for k, v in scores.items() if v>0}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2021-06-09 23:45:13,930 numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2058f7e849c94bba83225ba26f90ca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2355.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagging error: ？\n",
      "tagging error: ！？\n",
      "tagging error: ？？？\n",
      "tagging error: ？？！？！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asp_subdfr = aspects.loc[aspects.is_context==False, :]\n",
    "A_evals = {}\n",
    "A_words = {}\n",
    "A_ngrams = {}\n",
    "for A, V, r in tqdm(zip(asp_subdfr.attr_norm, \n",
    "                     asp_subdfr.evaltext, asp_subdfr.rating), total=asp_subdfr.shape[0]):\n",
    "    if isinstance(A, float) or isinstance(V, float): continue\n",
    "    V = V.strip()\n",
    "    try:\n",
    "        words = chain(*(tuple(w) for w in tagger.tag(V)))\n",
    "    except:\n",
    "        print(\"tagging error: \", end='')\n",
    "        print(V)\n",
    "        continue\n",
    "    A_words.setdefault(A, Counter()).update(words)\n",
    "    A_evals.setdefault(A, []).append((V, r))\n",
    "    ng_dict = A_ngrams.setdefault(A, {})\n",
    "    ngrams(V, ng_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug use\n",
    "from itertools import islice\n",
    "scores = {}\n",
    "attr, ng_dict = list(islice(A_ngrams.items(), 2, 3))[0]\n",
    "print(attr)\n",
    "wsize = sorted(ng_dict.keys())\n",
    "ngfreq = {k: freq for k, freq \n",
    "          in chain((*(ng_dict[w].items() for w in wsize)))}\n",
    "print(compute_score(\"麼優\", ngfreq, scores))\n",
    "del attr, ng_dict, scores, ngfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2bf68c6e094eb79e2735e848cbcdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A_ngrams = {k: compute_ngram_scores(ng_dict) \n",
    "            for k, ng_dict \n",
    "            in tqdm(A_ngrams.items())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for A in A_evals:    \n",
    "    data[A] = {\n",
    "        \"evals\": A_evals[A],\n",
    "        \"words\": sorted(A_words[A].items(), key=lambda x: -x[1]),\n",
    "        \"ngrams\": sorted(A_ngrams[A].items(), key=lambda x: (-x[1], -len(x[0])))\n",
    "    }    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_list = {k: list(chain(*([y[0]]*y[1] for y in x[\"ngrams\"]))) for k, x in data.items()}\n",
    "attr_list = list(ng_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "mat = tfidf.fit_transform(ng_list.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_tokens = tfidf.get_feature_names()\n",
    "ng_tokens.index(\"超慢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_tokens = tfidf.get_feature_names()\n",
    "for attr_i, attr in enumerate(attr_list):\n",
    "    attr_item = data[attr]\n",
    "    ngs = attr_item[\"ngrams\"]\n",
    "    new_ngs = []    \n",
    "    for ng, ngfreq in ngs:\n",
    "        score = mat[attr_i, ng_tokens.index(ng)]\n",
    "        new_ngs.append((ng, ngfreq, score))\n",
    "    new_ngs = sorted(new_ngs, key=lambda x: -x[2])\n",
    "    attr_item[\"ngrams\"] = new_ngs\n",
    "    data[attr] = attr_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = data_dir/r\"annot_data\\annotated_data_bkup\\20210605\\eval_ontology_raw.json\"\n",
    "with open(out_path, \"w\", encoding=\"UTF-8\") as fout:\n",
    "    json.dump(data, fout, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
