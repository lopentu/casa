{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from import_casa import casa\n",
    "from casa import caprice\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Microsoft JhengHei\"\n",
    "# plt.rcParams[\"font.family\"] = \"Heiti TC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../data/caprice/seq_shapley_data_rev.pkl\", \"rb\") as fin:\n",
    "    data = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../data/caprice/pos_list.txt\", \"r\") as fin:\n",
    "    pos_list = fin.readlines()\n",
    "pos_list = [x.strip() for x in pos_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified:  2429\n",
      "All instances:  2518\n",
      "Accuracy:  0.9646544876886418\n"
     ]
    }
   ],
   "source": [
    "n_correct = sum(x[1] == x[3] for x in data)\n",
    "print(\"Correctly classified: \", n_correct)\n",
    "print(\"All instances: \", len(data))\n",
    "print(\"Accuracy: \", n_correct/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[0]\n",
    "assert data_x[1] == data_x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_data = data_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_tokens',\n",
       " 'merged_tokens',\n",
       " 'values',\n",
       " 'group_sizes',\n",
       " 'upper_values',\n",
       " 'lower_values',\n",
       " 'group_values',\n",
       " 'max_values',\n",
       " 'token_id_to_node_id_mapping',\n",
       " 'collapsed_node_ids',\n",
       " 'pos_probs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shap_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, (15, 80))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[10][2][\"raw_tokens\"]), data[10][2][\"pos_probs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class ItemRecord:\n",
    "    value: float\n",
    "    freq: int\n",
    "    pos: np.ndarray\n",
    "        \n",
    "merged_values = defaultdict(lambda: ItemRecord(0,0,None))\n",
    "\n",
    "for data_x in data:\n",
    "    if data_x[1] != data_x[3]:\n",
    "        continue\n",
    "    shap_data = data_x[2]\n",
    "    tok2nd = shap_data[\"token_id_to_node_id_mapping\"]\n",
    "    group_values = shap_data[\"group_values\"]\n",
    "    raw_tokens = shap_data[\"raw_tokens\"]    \n",
    "    pos_probs = shap_data[\"pos_probs\"]\n",
    "    buf = \"\"\n",
    "    pos_buf = []\n",
    "    last_id = 0\n",
    "    \n",
    "    if data_x[1] == 1:\n",
    "        polarity = -1\n",
    "    elif data_x[1] == 2:\n",
    "        polarity = 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    for tok_id, nd_id in enumerate(tok2nd):    \n",
    "        raw_tok = raw_tokens[tok_id]\n",
    "        if last_id != nd_id:\n",
    "            nd_value = polarity*group_values[int(last_id)]\n",
    "            merged_values[buf].value += nd_value\n",
    "            merged_values[buf].freq += 1          \n",
    "            \n",
    "            if buf:\n",
    "                pos_vec = np.vstack(pos_buf)\n",
    "            else:\n",
    "                pos_vec = np.zeros((1, len(pos_list)), dtype=np.float32)\n",
    "                \n",
    "            if merged_values[buf].pos is not None:\n",
    "                if merged_values[buf].pos.shape[0] != pos_vec.shape[0]:\n",
    "                    breakpoint()\n",
    "                merged_values[buf].pos += pos_vec\n",
    "            else:\n",
    "                merged_values[buf].pos = pos_vec\n",
    "            pos_buf = []\n",
    "            buf = \"\"        \n",
    "                \n",
    "        last_id = nd_id\n",
    "        buf += raw_tok\n",
    "        if buf:\n",
    "            pos_buf.append(pos_probs[tok_id])\n",
    "        \n",
    "    if buf:\n",
    "        merged_values[buf].value += polarity*nd_value\n",
    "        merged_values[buf].freq += 1\n",
    "        if merged_values[buf].pos is not None:\n",
    "            merged_values[buf].pos += np.vstack(pos_buf)\n",
    "        else:\n",
    "            merged_values[buf].pos = np.vstack(pos_buf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "func_mask = [int(re.match(r\"N.+|V.+|.*CATEGORY\", x) is None) for x in pos_list]\n",
    "merged_pats = {}\n",
    "pos_pats = {}\n",
    "for pat, rec in merged_values.items():\n",
    "    if not pat: continue\n",
    "    merged_pats[pat] = rec.value / rec.freq\n",
    "    pos_pats[pat] = rec.pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('推一個中華電信', 7.870637995609361),\n",
       " ('中華電信好棒', 7.7634880861507565),\n",
       " ('五g只信亞太', 7.390305129533919),\n",
       " ('推薦中華', 7.274335797337526),\n",
       " ('中華好', 7.209806027316583),\n",
       " ('比較好👍', 6.879871856063669),\n",
       " ('還好中華', 6.662722067440681),\n",
       " ('看好中華', 6.316037732134994),\n",
       " ('只推台哥', 6.229564097269431),\n",
       " ('比較期待中華', 6.060835340858928)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, merged_pats[x]) for x in sorted(merged_pats.keys(), key=merged_pats.get, reverse=True)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('剛剛中華出問題', -8.240402194087654),\n",
       " ('台哥大日常斷線', -8.08578173037489),\n",
       " ('大真的夠爛', -8.019043184761369),\n",
       " ('台哥大靠限速就', -7.922424416351588),\n",
       " ('中華電信不考慮', -7.821020848328299),\n",
       " ('中華明顯變慢', -7.700923131146217),\n",
       " ('台哥-7 呵', -7.670989988222811),\n",
       " ('很快就爆了699收費太貴...', -7.652803886230502),\n",
       " ('再快中華電信還是一樣慢', -7.5941035827948244),\n",
       " ('人用中華自然慢', -7.570727740488522)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, merged_pats[x]) for x in sorted(merged_pats.keys(), key=merged_pats.get, reverse=False)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = {}\n",
    "for pat, pos_probs in pos_pats.items():\n",
    "    pos_weights[pat] = (pos_probs * np.array(func_mask)).mean(axis=0).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DistilTag import DistilTag\n",
    "tagger = DistilTag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這_0.50 Nep_0.42/ Dk_0.04/Nes_0.03/Cbb_0.02/SHI_0.02\n",
      "一_0.51 Neu_0.63/Cbb_0.02/ Nb_0.02/ FW_0.02/ Nd_0.01\n",
      "個_0.48  Nf_0.41/ Nh_0.04/ Na_0.03/ Nc_0.03/ Nd_0.02\n",
      "比_0.59 Dfa_0.57/ VC_0.03/ Na_0.02/V_2_0.02/ Nv_0.02\n",
      "較_0.39 Dfa_0.64/ VH_0.02/ VC_0.02/ Nf_0.02/ Nv_0.01\n",
      "好_0.49  VH_0.59/ VL_0.03/ VC_0.03/ VA_0.02/ Nv_0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger.print_soft_tag(*tagger.soft_tag(\"這一個比較好\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(\"N[^ef]+\", \"Neu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = [int(re.match(r\"V.+\", x) is not None) for x in pos_list]\n",
    "D = [int(re.match(r\"D.+\", x) is not None) for x in pos_list]\n",
    "NDet = [int(re.match(r\"Ne.|Nf\", x) is not None) for x in pos_list]\n",
    "NN = [int(re.match(r\"N[^ef]+\", x) is not None) for x in pos_list]\n",
    "def make_mask(*masks):\n",
    "    cons_mask = np.vstack([*masks]).astype(np.float32)\n",
    "    cons_mask /= cons_mask.sum()\n",
    "    return cons_mask\n",
    "cons_masks = {\n",
    "    \"DDVV\": make_mask([D, D, V, V]),\n",
    "    \"DDV\": make_mask([D, D, V]),\n",
    "    \"DVV\": make_mask([D, V, V]),\n",
    "    \"Nd2N\": make_mask([NDet, NDet, NN]),\n",
    "    \"NdN2\": make_mask([NDet, NN, NN])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cross_product(pos_mat, cons_mask):\n",
    "    mask_M = cons_mask.shape[0]\n",
    "    res_M = pos_mat.shape[0]-mask_M+1\n",
    "    if res_M <= 0:\n",
    "        return np.zeros((1, 1), dtype=np.float32)\n",
    "    res_mat = np.zeros(shape=(res_M, 1))\n",
    "    for i in range(res_M):\n",
    "        res_mat[i] = (pos_mat[i:i+mask_M] * cons_mask).sum()\n",
    "    return res_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(pos_mat, masks):\n",
    "    scores = np.zeros(len(masks), dtype=np.float32)\n",
    "    for mask_i, mask_x in enumerate(masks):\n",
    "        scores[mask_i] = apply_cross_product(pos_mat, mask_x).max()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06581572, 0.07206085, 0.06067116, 0.03702857, 0.06047242],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_masks(pos_pats[\"比較期待中華\"], cons_masks.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_pats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley values quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.28107910e-04, 4.93802306e-02, 1.08744117e-01, 1.61021417e-01,\n",
       "       2.36114685e-01, 3.51826612e-01, 4.73569859e-01, 7.15314132e-01,\n",
       "       1.38131416e+00, 5.38047525e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.abs([x for pat, x in merged_pats.items() if 3<=len(pat)<=10]), np.arange(0,1,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern weights distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_weights_1 = {}\n",
    "pat_weights_2 = {}\n",
    "for pat in merged_pats:\n",
    "    pol_value = merged_pats[pat]\n",
    "    pos_score = pos_weights[pat].mean()    \n",
    "    # pat_weights_1[pat] = pol_value/abs(pol_value) * (len(pat)*20 + pos_score*.5 + abs(pol_value)*.5)\n",
    "    pat_weights_1[pat] = pol_value/abs(pol_value) * (len(pat)*20 + abs(pol_value))\n",
    "    pat_weights_2[pat] = (pol_value/abs(pol_value) * \n",
    "                          (apply_masks(pos_pats[pat], cons_masks.values()).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.04639961, 0.05843211,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(list(pat_weights_2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02019217, 0.03824183, 0.05375126, 0.06033709, 0.0606324 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.abs([x for pat, x in pat_weights_2.items() if 3<=len(pat)<=10]), np.arange(0,1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dict_x, key_func, reverse=True, topn=10):\n",
    "    return [(x, dict_x[x]) for x in sorted(dict_x.keys(), key=key_func, reverse=reverse)][:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"h:/pat.txt\", \"w\", encoding=\"UTF-8\") as fout:\n",
    "# with open(\"h:/pat.txt\", \"w\", encoding=\"UTF-8\") as fout:\n",
    "    for x in sort_dict(merged_pats, \n",
    "                       key_func=lambda x: (pat_weights_1.get(x)), \n",
    "                       reverse=True, topn=-1):\n",
    "        if not (3 <= len(x[0]) <= 10): continue\n",
    "        if abs(x[1]) <= 2: continue\n",
    "        fout.write(f\"{x[0]}, {pos_weights[x[0]].sum():.4f}, {pat_weights_1[x[0]]:.4f}\")\n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"h:/pat2.txt\", \"w\", encoding=\"UTF-8\") as fout:\n",
    "# with open(\"h:/pat.txt\", \"w\", encoding=\"UTF-8\") as fout:\n",
    "    for x in sort_dict(merged_pats, \n",
    "                       key_func=lambda x: (pat_weights_2.get(x)), \n",
    "                       reverse=True, topn=-1):\n",
    "        if not (3 <= len(x[0]) <= 10): continue\n",
    "        weight = pat_weights_2[x[0]]\n",
    "        if abs(x[1]) <= 0.496: continue\n",
    "        if abs(weight) <= .0202: continue\n",
    "        fout.write(f\"{x[0]};{x[1]:.4f};{weight:.4f}\")\n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
