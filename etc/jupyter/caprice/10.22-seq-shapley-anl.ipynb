{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seantyh/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from import_casa import casa\n",
    "from casa import caprice\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Microsoft JhengHei\"\n",
    "# plt.rcParams[\"font.family\"] = \"Heiti TC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../data/caprice/seq_shapley_data_rev.pkl\", \"rb\") as fin:\n",
    "    data = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../data/caprice/pos_list.txt\", \"r\") as fin:\n",
    "    pos_list = fin.readlines()\n",
    "pos_list = [x.strip() for x in pos_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified:  2429\n",
      "All instances:  2518\n",
      "Accuracy:  0.9646544876886418\n"
     ]
    }
   ],
   "source": [
    "n_correct = sum(x[1] == x[3] for x in data)\n",
    "print(\"Correctly classified: \", n_correct)\n",
    "print(\"All instances: \", len(data))\n",
    "print(\"Accuracy: \", n_correct/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[0]\n",
    "assert data_x[1] == data_x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_data = data_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_tokens',\n",
       " 'merged_tokens',\n",
       " 'values',\n",
       " 'group_sizes',\n",
       " 'upper_values',\n",
       " 'lower_values',\n",
       " 'group_values',\n",
       " 'max_values',\n",
       " 'token_id_to_node_id_mapping',\n",
       " 'collapsed_node_ids',\n",
       " 'pos_probs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shap_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, (15, 80))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[10][2][\"raw_tokens\"]), data[10][2][\"pos_probs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class ItemRecord:\n",
    "    value: float\n",
    "    freq: int\n",
    "    pos: np.ndarray\n",
    "        \n",
    "merged_values = defaultdict(lambda: ItemRecord(0,0,None))\n",
    "\n",
    "for data_x in data:\n",
    "    if data_x[1] != data_x[3]:\n",
    "        continue\n",
    "    shap_data = data_x[2]\n",
    "    tok2nd = shap_data[\"token_id_to_node_id_mapping\"]\n",
    "    group_values = shap_data[\"group_values\"]\n",
    "    raw_tokens = shap_data[\"raw_tokens\"]    \n",
    "    pos_probs = shap_data[\"pos_probs\"]\n",
    "    buf = \"\"\n",
    "    pos_buf = []\n",
    "    last_id = 0\n",
    "    \n",
    "    if data_x[1] == 1:\n",
    "        polarity = -1\n",
    "    elif data_x[1] == 2:\n",
    "        polarity = 2\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    for tok_id, nd_id in enumerate(tok2nd):    \n",
    "        raw_tok = raw_tokens[tok_id]\n",
    "        if last_id != nd_id:\n",
    "            nd_value = polarity*group_values[int(last_id)]\n",
    "            merged_values[buf].value += nd_value\n",
    "            merged_values[buf].freq += 1          \n",
    "            \n",
    "            if buf:\n",
    "                pos_vec = np.vstack(pos_buf)\n",
    "            else:\n",
    "                pos_vec = np.zeros((1, len(pos_list)), dtype=np.float32)\n",
    "                \n",
    "            if merged_values[buf].pos is not None:\n",
    "                if merged_values[buf].pos.shape[0] != pos_vec.shape[0]:\n",
    "                    breakpoint()\n",
    "                merged_values[buf].pos += pos_vec\n",
    "            else:\n",
    "                merged_values[buf].pos = pos_vec\n",
    "            pos_buf = []\n",
    "            buf = \"\"        \n",
    "                \n",
    "        last_id = nd_id\n",
    "        buf += raw_tok\n",
    "        if buf:\n",
    "            pos_buf.append(pos_probs[tok_id])\n",
    "        \n",
    "    if buf:\n",
    "        merged_values[buf].value += polarity*nd_value\n",
    "        merged_values[buf].freq += 1\n",
    "        if merged_values[buf].pos is not None:\n",
    "            merged_values[buf].pos += np.vstack(pos_buf)\n",
    "        else:\n",
    "            merged_values[buf].pos = np.vstack(pos_buf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "func_mask = [int(re.match(r\"N.+|V.+|.*CATEGORY\", x) is None) for x in pos_list]\n",
    "merged_pats = {}\n",
    "pos_pats = {}\n",
    "for pat, rec in merged_values.items():\n",
    "    if not pat: continue\n",
    "    merged_pats[pat] = rec.value / rec.freq\n",
    "    pos_pats[pat] = rec.pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('推一個中華電信', 15.741275991218721),\n",
       " ('中華電信好棒', 15.526976172301513),\n",
       " ('五g只信亞太', 14.780610259067839),\n",
       " ('推薦中華', 14.548671594675053),\n",
       " ('中華好', 14.419612054633166),\n",
       " ('比較好👍', 13.759743712127339),\n",
       " ('還好中華', 13.325444134881362),\n",
       " ('看好中華', 12.632075464269988),\n",
       " ('只推台哥', 12.459128194538861),\n",
       " ('比較期待中華', 12.121670681717855)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, merged_pats[x]) for x in sorted(merged_pats.keys(), key=merged_pats.get, reverse=True)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('在北大武三角', -8.82558056486867),\n",
       " ('剛剛中華出問題', -8.240402194087654),\n",
       " ('台哥大日常斷線', -8.08578173037489),\n",
       " ('大真的夠爛', -8.019043184761369),\n",
       " ('台哥大靠限速就', -7.922424416351588),\n",
       " ('中華電信不考慮', -7.821020848328299),\n",
       " ('中華學生方案', -7.715885746963345),\n",
       " ('中華明顯變慢', -7.700923131146217),\n",
       " ('台哥-7 呵', -7.670989988222811),\n",
       " ('很快就爆了699收費太貴...', -7.652803886230502)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, merged_pats[x]) for x in sorted(merged_pats.keys(), key=merged_pats.get, reverse=False)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = {}\n",
    "for pat, pos_probs in pos_pats.items():\n",
    "    pos_weights[pat] = (pos_probs * np.array(func_mask)).mean(axis=0).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_weights_1 = {}\n",
    "for pat in merged_pats:\n",
    "    pol_value = merged_pats[pat]\n",
    "    pos_score = pos_weights[pat].mean()    \n",
    "    # pat_weights_1[pat] = pol_value/abs(pol_value) * (len(pat)*20 + pos_score*.5 + abs(pol_value)*.5)\n",
    "    pat_weights_1[pat] = pol_value/abs(pol_value) * (len(pat)*20 + abs(pol_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dict_x, key_func, reverse=True, topn=10):\n",
    "    return [(x, dict_x[x]) for x in sorted(dict_x.keys(), key=key_func, reverse=reverse)][:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/pat.txt\", \"w\", encoding=\"UTF-8\") as fout:\n",
    "    for x in sort_dict(merged_pats, \n",
    "                       key_func=lambda x: (pat_weights_1.get(x)), \n",
    "                       reverse=True, topn=-1):\n",
    "        if not (3 <= len(x[0]) <= 10): continue\n",
    "        if abs(x[1]) <= 2: continue\n",
    "        fout.write(f\"{x[0]}, {pos_weights[x[0]].sum():.4f}, {pat_weights_1[x[0]]:.4f}\")\n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x = pos_pats[\"遠傳然後\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
