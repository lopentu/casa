{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from import_casa import casa, cano\n",
    "from casa.annot import AspectEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(6523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../../data/caprice/caprice_seq_data_20210430.pkl\")\n",
    "with data_path.open(\"rb\") as fin:\n",
    "    data = pickle.load(fin)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = casa.get_data_path() / \"caprice/seq-model-ep9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"測試自串\"\n",
    "batch = tokenizer([txt], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dial = 10.\n",
    "out = model(**batch, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.1572, -1.6533, -2.0265]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out.logits)\n",
    "out.logits[0,1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_hidden = np.dstack([x[0, 0, :].detach().numpy() for x in out.hidden_states]).squeeze().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 768)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import DictionaryLearning, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.9375"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000*768*12*8/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to NMF (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-3820220f584d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnmf_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         W, H, n_iter_ = non_negative_factorization(\n\u001b[0m\u001b[0;32m   1282\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m             \u001b[0mupdate_H\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m     \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NMF (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m     \u001b[0mbeta_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_string_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to NMF (input X)"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=10)\n",
    "nmf_W = nmf.fit_transform(cls_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:174: RuntimeWarning:  Orthogonal matching pursuit ended prematurely due to linear\n",
      "dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "  new_code = orthogonal_mp_gram(\n"
     ]
    }
   ],
   "source": [
    "dict_learn = DictionaryLearning(n_components=10)\n",
    "code = dict_learn.fit_transform(cls_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.36585426e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.11160717e+01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.52054195e+01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-2.24791050e-01, -1.89658236e-02, -4.27643508e-02,\n",
       "         5.57002909e-02,  1.77728847e-01, -2.21914887e-01,\n",
       "         1.62942848e+01, -5.20834029e-01, -1.60758123e-02,\n",
       "         1.19345132e-02],\n",
       "       [ 6.33432925e-01,  4.91444282e-02,  1.05040967e-01,\n",
       "        -1.41664907e-01, -4.51044440e-01,  5.58365703e-01,\n",
       "         6.24289274e+00,  9.76596355e+00,  4.17317450e-02,\n",
       "        -2.91319005e-02],\n",
       "       [-1.50274467e+00, -2.87434608e-02,  7.10701272e-02,\n",
       "         2.12752633e-02,  4.60230075e-02,  5.19600101e-02,\n",
       "         1.03911579e+00,  1.20656071e+01, -2.61731427e-02,\n",
       "        -2.40977667e-02],\n",
       "       [-2.53082156e+00, -3.13788140e-03, -5.44814840e-02,\n",
       "         1.43336937e-01,  9.78536159e-02, -4.78552669e-01,\n",
       "        -3.87372881e-01,  1.11818380e+01, -2.32501347e-02,\n",
       "         1.33818630e-02],\n",
       "       [-4.65747070e+00, -3.50329909e-03, -1.28763944e-01,\n",
       "        -1.82009097e-02,  1.62837133e-01, -2.38014638e-01,\n",
       "        -8.16779852e-01,  9.81320572e+00,  1.36675257e-02,\n",
       "         5.02659082e-02],\n",
       "       [-8.93880749e+00,  5.66010084e-03, -8.19959491e-02,\n",
       "        -6.87396973e-02,  2.31262505e-01,  8.60002860e-02,\n",
       "        -7.31255770e-01,  6.21400738e+00,  1.79596227e-02,\n",
       "         3.48407440e-02],\n",
       "       [-1.66167850e+01, -2.94768647e-03, -3.79390493e-02,\n",
       "         4.14431915e-02,  6.92757592e-02,  1.12517677e-01,\n",
       "        -2.60441214e-01,  2.13371992e+00,  1.67999435e-02,\n",
       "        -4.17152680e-02],\n",
       "       [-1.92821617e+01,  3.46754515e-03,  8.93745478e-03,\n",
       "        -5.21577671e-02, -8.69440064e-02,  1.86801124e-02,\n",
       "         5.65587044e-01, -1.28698945e+00, -1.57122407e-02,\n",
       "         0.00000000e+00],\n",
       "       [-1.42284803e+01, -3.00507457e-03,  1.85128957e-01,\n",
       "         4.39681672e-02, -2.59874463e-01,  2.49159406e-03,\n",
       "         6.13828182e-01, -2.18027902e+00, -1.41624557e-02,\n",
       "         1.51195133e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  2.24060154e+01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0405e-03, -4.1365e-03,  1.3692e-03,  ...,  1.8974e-03,\n",
       "          -3.4728e-04,  3.0908e-04],\n",
       "         [ 4.6576e-04,  3.2694e-03, -2.6202e-03,  ...,  1.5930e-03,\n",
       "           2.4502e-03,  5.5137e-03],\n",
       "         [ 1.9376e-03,  2.8792e-03,  1.2040e-03,  ..., -5.3440e-04,\n",
       "          -1.1346e-03,  3.0696e-03],\n",
       "         [-2.4427e-03, -4.8167e-03,  5.7168e-03,  ..., -3.1514e-03,\n",
       "          -2.7876e-03,  5.2438e-03],\n",
       "         [-1.1823e-03, -3.8804e-03,  8.1164e-04,  ...,  1.3053e-03,\n",
       "          -2.1243e-05, -7.6663e-03],\n",
       "         [-8.8982e-04, -6.6297e-04,  6.3790e-04,  ..., -4.3090e-04,\n",
       "          -2.2132e-03,  1.3988e-03]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 3072])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = None\n",
    "output_ = None\n",
    "\n",
    "def im_forward_hook(mod, input_state, output_state):\n",
    "    global input_, output_\n",
    "    output_state[0,0,:] *= dial\n",
    "    output_state.retain_grad()\n",
    "    input_ = input_state\n",
    "    output_ = output_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()\n",
    "handle = bert.encoder.layer[0].intermediate.register_forward_hook(im_forward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertIntermediate(\n",
       "  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.encoder.layer[0].intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (1): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (2): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (3): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (4): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (5): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (6): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (7): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (8): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (9): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (10): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (11): BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.encoder.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3072/768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
