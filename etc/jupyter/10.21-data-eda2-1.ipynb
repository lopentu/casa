{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_casa import casa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_path = casa.get_data_path()\n",
    "with open(data_path / \"raw-data-cht-202010.pkl\", \"rb\") as fin:\n",
    "    threads = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7772"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#ÂïèÈ°å 499ÊØçË¶™ÁØÄÊñπÊ°àË¶ÅÁ∫åÁ¥ÑÂóé\\u3000ÊúÄËøëÂêÑÂÆ∂Èõª‰ø°‰∏ÄÁõ¥ÊâìÈõªË©±ÂÇ≥Á∞°Ë®äË©¢ÂïèË¶Å‰∏çË¶ÅÁ∫åÁ¥Ñ ÊúâÂ§†ÁÖ©ÁöÑ‰ΩÜÁï¢Á´üÂêàÁ¥ÑÊúâ30ÂÄãÊúà ËÄå5GÊú™‰æÜÊúÉÊôÆÂèä‰πüÊòØ‰∏çËÆä‰∫ãÂØ¶(?ÊÉ≥ÂïèÊùø‰∏äÂ§ßÂ§ßË¶∫ÂæóË¶ÅÁ∫åÁ¥ÑÂóéÔºüÈÇÑÊòØÁ≠âÂêàÁ¥ÑÂà∞Êúü Áõ¥Êé•Á∫å488Â≠∏ÁîüÊñπÊ°àÂë¢Ôºü',\n",
       " 'Á∫å',\n",
       " 'B1 ÊÄéÈ∫ºË™™',\n",
       " '5gÁèæÂú®ÈÇÑ‰∏çÁ©©ÂÆö ÁèæÂú®Ëæ¶5gÁπ≥5gÁöÑÈå¢Âè™ËÉΩ‰∫´Âèó4g Ôºå5gÂÖ®Âè∞Âü∫Âú∞Âè∞Âè™ÊúâÊüê‰∫õÂú∞ÊñπÊØîËºÉÁ©© ÁîöËá≥Êúâ‰∫õÂú∞ÊñπÈÄ£4gÈÉΩÊúâÂïèÈ°å ÂèØËÉΩÈÇÑË¶Å1.2Âπ¥ÊâçÊúÉÊôÆÂèä ÂÄã‰∫∫ÁúãÊ≥ï',\n",
       " 'B3 ÊâÄ‰ª•‰πü‰∏çÂª∫Ë≠∞ÁèæÂú®Â∞±Êèõ5gÊâãÊ©üÂõâÔºü',\n",
       " 'Êèõ5gÊâãÊ©üÂèØ‰ª• ‰ΩÜÊòØ5gÁ∂≤Ë∑ØÂèØ‰ª•ÂÜçÁ≠âÁ≠â Â¶ÇÊûú1.2Âπ¥ÂÖß‰∏çÊúÉÁî≥Ëæ¶5gÁ∂≤Ë∑Ø Ë¶∫ÂæóÊãø4gÊâãÊ©üÂ∞±Â§†Áî®‰∫Ü B4',\n",
       " 'B5 Â•ΩÁöÑ~',\n",
       " 'ÊàëËá™Â∑± ÈÇÑÊúâÂÆ∂‰∫∫ÂíåÂêåÂ≠∏ ÈÉΩÊòØÁ∫å30ÂÄãÊúà B6',\n",
       " 'Á≠â1111',\n",
       " 'B8 1111ÊòØÊâãÊ©üÊñπÊ°àÂà∞ÊúüÊó•ÂóéüòÇ',\n",
       " 'B9ÂêÑÂ§ßÈõª‰ø°ÂÑ™ÊÉ†Êó•']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(threads[0].opinion_texts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = data_path / \"opinion_texts.cht-202010.txt\"\n",
    "with out_path.open(\"w\", encoding=\"UTF-8\") as fout:\n",
    "    try:\n",
    "        for thread_x in threads:\n",
    "            fout.write(\"\\n\".join(thread_x.opinion_texts()))\n",
    "    except:\n",
    "        print(list(thread_x.opinion_texts()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train(input=out_path, vocab_size=6000, \n",
    "                               model_prefix=\"../../data/eda/spm/cht-202010\", \n",
    "                               model_type=\"bpe\",\n",
    "                               add_dummy_prefix=False,\n",
    "                               split_by_unicode_script=False,                                \n",
    "                               split_by_number=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file=\"../../data/eda/spm/cht-202010.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process by SPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_processor = casa.SpmEdaProcessor(\"../../data/eda/spm/cht-202010.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [x.process(sp_processor) for x in threads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, islice\n",
    "from collections import Counter\n",
    "op_tokens_iter = (x.opinion_tokens() for x in threads)\n",
    "thread_tokens_iter = chain.from_iterable(op_tokens_iter)\n",
    "flat_tokens_iter = chain.from_iterable(thread_tokens_iter)\n",
    "preproc_iter = map(lambda x: x.replace(\"‚ñÅ\", \"\"), flat_tokens_iter)\n",
    "spm_freq = Counter(preproc_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_spm = sorted(spm_freq.most_common(), key=lambda x: (-len(x[0]), -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spm_frame = pd.DataFrame.from_records(sorted_spm, columns=[\"token\", \"freq\"])\n",
    "spm_frame = spm_frame.loc[spm_frame.token.str.len() > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_frame.to_csv(\"../../data/eda/spm/spm_frequency.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-11-24 15:39:09,733 gensim.models.word2vec: resetting layer weights\n",
      "[INFO] 2020-11-24 15:39:16,851 gensim.models.word2vec: collecting all words and their counts\n",
      "[INFO] 2020-11-24 15:39:16,852 gensim.models.word2vec: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "[INFO] 2020-11-24 15:39:16,928 gensim.models.word2vec: PROGRESS: at sentence #10000, processed 484463 words, keeping 5279 word types\n",
      "[INFO] 2020-11-24 15:39:16,999 gensim.models.word2vec: PROGRESS: at sentence #20000, processed 929943 words, keeping 5905 word types\n",
      "[INFO] 2020-11-24 15:39:17,061 gensim.models.word2vec: PROGRESS: at sentence #30000, processed 1354191 words, keeping 6283 word types\n",
      "[INFO] 2020-11-24 15:39:17,125 gensim.models.word2vec: PROGRESS: at sentence #40000, processed 1762574 words, keeping 6578 word types\n",
      "[INFO] 2020-11-24 15:39:17,128 gensim.models.word2vec: collected 6581 word types from a corpus of 1768673 raw words and 40135 sentences\n",
      "[INFO] 2020-11-24 15:39:17,131 gensim.models.word2vec: Loading a fresh vocabulary\n",
      "[INFO] 2020-11-24 15:39:17,151 gensim.models.word2vec: effective_min_count=2 retains 5885 unique words (89% of original 6581, drops 696)\n",
      "[INFO] 2020-11-24 15:39:17,152 gensim.models.word2vec: effective_min_count=2 leaves 1767977 word corpus (99% of original 1768673, drops 696)\n",
      "[INFO] 2020-11-24 15:39:17,185 gensim.models.word2vec: deleting the raw counts dictionary of 6581 items\n",
      "[INFO] 2020-11-24 15:39:17,186 gensim.models.word2vec: sample=0.001 downsamples 33 most-common words\n",
      "[INFO] 2020-11-24 15:39:17,187 gensim.models.word2vec: downsampling leaves estimated 1635711 word corpus (92.5% of prior 1767977)\n",
      "[INFO] 2020-11-24 15:39:17,232 gensim.models.fasttext: estimated required memory for 5885 words, 11279 buckets and 100 dimensions: 12545268 bytes\n",
      "[INFO] 2020-11-24 15:39:17,233 gensim.models.word2vec: resetting layer weights\n",
      "[INFO] 2020-11-24 15:39:22,364 gensim.models.base_any2vec: training model with 3 workers on 5885 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "[INFO] 2020-11-24 15:39:23,378 gensim.models.base_any2vec: EPOCH 1 - PROGRESS: at 42.71% examples, 755962 words/s, in_qsize 5, out_qsize 2\n",
      "[INFO] 2020-11-24 15:39:24,257 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:24,264 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:24,283 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:24,284 gensim.models.base_any2vec: EPOCH - 1 : training on 1768673 raw words (1626623 effective words) took 1.9s, 849258 effective words/s\n",
      "[INFO] 2020-11-24 15:39:25,288 gensim.models.base_any2vec: EPOCH 2 - PROGRESS: at 55.46% examples, 1025772 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:25,970 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:25,987 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:25,994 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:25,995 gensim.models.base_any2vec: EPOCH - 2 : training on 1768673 raw words (1626853 effective words) took 1.7s, 952849 effective words/s\n",
      "[INFO] 2020-11-24 15:39:27,005 gensim.models.base_any2vec: EPOCH 3 - PROGRESS: at 46.20% examples, 794027 words/s, in_qsize 6, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:27,862 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:27,869 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:27,874 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:27,875 gensim.models.base_any2vec: EPOCH - 3 : training on 1768673 raw words (1626720 effective words) took 1.9s, 866523 effective words/s\n",
      "[INFO] 2020-11-24 15:39:28,895 gensim.models.base_any2vec: EPOCH 4 - PROGRESS: at 58.18% examples, 1036810 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:29,531 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:29,539 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:29,554 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:29,556 gensim.models.base_any2vec: EPOCH - 4 : training on 1768673 raw words (1626670 effective words) took 1.7s, 970076 effective words/s\n",
      "[INFO] 2020-11-24 15:39:30,570 gensim.models.base_any2vec: EPOCH 5 - PROGRESS: at 42.08% examples, 745639 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:31,580 gensim.models.base_any2vec: EPOCH 5 - PROGRESS: at 96.60% examples, 773937 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:31,644 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:31,659 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:31,684 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:31,686 gensim.models.base_any2vec: EPOCH - 5 : training on 1768673 raw words (1626554 effective words) took 2.1s, 765325 effective words/s\n",
      "[INFO] 2020-11-24 15:39:32,701 gensim.models.base_any2vec: EPOCH 6 - PROGRESS: at 39.83% examples, 699308 words/s, in_qsize 4, out_qsize 1\n",
      "[INFO] 2020-11-24 15:39:33,607 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:33,617 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:33,631 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:33,632 gensim.models.base_any2vec: EPOCH - 6 : training on 1768673 raw words (1626325 effective words) took 1.9s, 837768 effective words/s\n",
      "[INFO] 2020-11-24 15:39:34,641 gensim.models.base_any2vec: EPOCH 7 - PROGRESS: at 60.08% examples, 1080451 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:35,256 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:35,270 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:35,275 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:35,276 gensim.models.base_any2vec: EPOCH - 7 : training on 1768673 raw words (1627025 effective words) took 1.6s, 991920 effective words/s\n",
      "[INFO] 2020-11-24 15:39:36,309 gensim.models.base_any2vec: EPOCH 8 - PROGRESS: at 40.41% examples, 704849 words/s, in_qsize 6, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:37,262 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:37,267 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:37,286 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:37,287 gensim.models.base_any2vec: EPOCH - 8 : training on 1768673 raw words (1626573 effective words) took 2.0s, 810308 effective words/s\n",
      "[INFO] 2020-11-24 15:39:38,292 gensim.models.base_any2vec: EPOCH 9 - PROGRESS: at 60.57% examples, 1092260 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:38,818 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:38,822 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:38,842 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:38,843 gensim.models.base_any2vec: EPOCH - 9 : training on 1768673 raw words (1626640 effective words) took 1.6s, 1046841 effective words/s\n",
      "[INFO] 2020-11-24 15:39:39,852 gensim.models.base_any2vec: EPOCH 10 - PROGRESS: at 42.08% examples, 750009 words/s, in_qsize 6, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:40,869 gensim.models.base_any2vec: EPOCH 10 - PROGRESS: at 92.09% examples, 733027 words/s, in_qsize 5, out_qsize 0\n",
      "[INFO] 2020-11-24 15:39:41,042 gensim.models.base_any2vec: worker thread finished; awaiting finish of 2 more threads\n",
      "[INFO] 2020-11-24 15:39:41,057 gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "[INFO] 2020-11-24 15:39:41,059 gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "[INFO] 2020-11-24 15:39:41,060 gensim.models.base_any2vec: EPOCH - 10 : training on 1768673 raw words (1627152 effective words) took 2.2s, 735792 effective words/s\n",
      "[INFO] 2020-11-24 15:39:41,061 gensim.models.base_any2vec: training on a 17686730 raw words (16267135 effective words) took 18.7s, 870132 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "import re\n",
    "pat = re.compile(\"[,‚ñÅ]\")\n",
    "def sanitize(x):    \n",
    "    return pat.sub(\"\", x)\n",
    "\n",
    "op_tokens_iter = (x.opinion_tokens() for x in threads)\n",
    "thread_tokens = chain.from_iterable(op_tokens_iter)\n",
    "thread_tokens = list(map(lambda tokens: [sanitize(x) for x in tokens], thread_tokens))\n",
    "    \n",
    "model = FastText(size=100, window=5, min_count=2)\n",
    "model.build_vocab(sentences=thread_tokens)\n",
    "model.train(sentences=thread_tokens, total_examples=len(thread_tokens), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Âè∞ÁÅ£Â§ß', 0.7099623680114746),\n",
       " ('‰∏≠ËèØÈõª', 0.6874696016311646),\n",
       " ('Âè∞ÁÅ£‰πãÊòüÁöÑ', 0.6767827272415161),\n",
       " ('‰∫ûÂ§™Èõª', 0.6112518310546875),\n",
       " ('„ÄÇÈÅ†ÂÇ≥', 0.6010882258415222),\n",
       " ('‰∏≠ËèØÈõª‰ø°ÁöÑ', 0.5904132723808289),\n",
       " ('ÈÅ†ÂÇ≥', 0.5849370956420898),\n",
       " ('‰ªäÊó•', 0.5521818399429321),\n",
       " ('#iPhone', 0.5488035678863525),\n",
       " ('ÂØ¶È´îÈñÄÂ∏Ç', 0.546295702457428),\n",
       " ('Á∂≤Ë∑ØÈñÄÂ∏Ç', 0.5450388789176941),\n",
       " ('iPhone', 0.5425416231155396),\n",
       " ('„ÄÇ‰∏≠ËèØÈõª‰ø°', 0.5404197573661804),\n",
       " ('‰∫ûÂ§™5G', 0.5296310782432556),\n",
       " ('Âè∞Âì•Â§ß', 0.5261499881744385),\n",
       " ('12„ÄÅiPhone', 0.525742769241333),\n",
       " ('‰∫ûÂ§™ÁöÑ', 0.5132642984390259),\n",
       " ('Èõª‰ø°‰∏âÈõÑ', 0.501976728439331),\n",
       " ('iPhone12', 0.5016946792602539),\n",
       " ('ÂíåÈÅ†ÂÇ≥', 0.500913679599762)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"‰∏≠ËèØÈõª‰ø°\", \"ÈÅ†ÂÇ≥Èõª‰ø°\", \"Âè∞ÁÅ£Â§ßÂì•Â§ß\", \"Âè∞ÁÅ£‰πãÊòü\", \"‰∫ûÂ§™Èõª‰ø°\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04915698,  0.45745426,  0.41741407,  0.1977035 ,  0.07172263,\n",
       "       -0.5270766 ,  0.12231938, -0.01552046, -0.18223609, -0.0202192 ,\n",
       "       -0.03669434, -0.43246984, -0.35885167, -0.1331142 ,  0.17527956,\n",
       "       -0.11173597,  0.28620502,  0.02082222,  0.01726513,  0.05518986,\n",
       "       -0.2388872 ,  0.2915667 ,  0.2661886 ,  0.15432915,  0.33016172,\n",
       "        0.6088445 ,  0.08653054,  0.133386  , -0.00344209, -0.03395419,\n",
       "        0.01283646, -0.30415154, -0.76913995, -0.16977854,  0.10662071,\n",
       "        0.24383529,  0.18520495,  0.05134694, -0.21708278,  0.12188572,\n",
       "        0.1289382 ,  0.08620791,  0.1799437 ,  0.19648352, -0.11858976,\n",
       "       -0.20809227, -0.3062387 , -0.11886251, -0.22456175, -0.2663437 ,\n",
       "        0.22548397,  0.11629876, -0.1063494 , -0.00578792,  0.01329483,\n",
       "       -0.02728292,  0.20289893,  0.07384316,  0.16674879,  0.12767471,\n",
       "       -0.29119405, -0.18927856,  0.00709701,  0.21857251, -0.31414282,\n",
       "       -0.1892137 ,  0.14208838, -0.08353277, -0.09640163,  0.15924342,\n",
       "        0.01954397, -0.3427769 , -0.278014  ,  0.01036971,  0.08681792,\n",
       "        0.02773467, -0.06242128,  0.16415566, -0.37178838, -0.08666728,\n",
       "       -0.2920376 , -0.20670226, -0.02011189,  0.2500692 ,  0.04451795,\n",
       "        0.11459046,  0.06872625, -0.30275092, -0.05374183,  0.16697536,\n",
       "        0.47597566,  0.16470581, -0.38515437, -0.20583075,  0.1938562 ,\n",
       "        0.03461267,  0.19513324, -0.5081624 , -0.01080999, -0.381276  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector(\"123123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5885"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-11-24 15:53:01,713 gensim.utils: saving FastText object under ../../data/eda/spm/sp_vectors.model, separately None\n",
      "[INFO] 2020-11-24 15:53:01,715 gensim.utils: storing np array 'vectors_ngrams' to ../../data/eda/spm/sp_vectors.model.wv.vectors_ngrams.npy\n",
      "[INFO] 2020-11-24 15:53:09,675 gensim.utils: not storing attribute vectors_ngrams_norm\n",
      "[INFO] 2020-11-24 15:53:09,676 gensim.utils: not storing attribute vectors_norm\n",
      "[INFO] 2020-11-24 15:53:09,677 gensim.utils: not storing attribute vectors_vocab_norm\n",
      "[INFO] 2020-11-24 15:53:09,677 gensim.utils: not storing attribute buckets_word\n",
      "[INFO] 2020-11-24 15:53:09,678 gensim.utils: storing np array 'vectors_ngrams_lockf' to ../../data/eda/spm/sp_vectors.model.trainables.vectors_ngrams_lockf.npy\n",
      "[INFO] 2020-11-24 15:53:18,839 gensim.utils: saved ../../data/eda/spm/sp_vectors.model\n"
     ]
    }
   ],
   "source": [
    "model.wv.save(\"../../data/eda/spm/sp_vectors.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-11-24 16:15:20,954 gensim.utils: loading FastText object from ../../data/eda/spm/sp_vectors.model\n",
      "[INFO] 2020-11-24 16:15:21,049 gensim.utils: loading wv recursively from ../../data/eda/spm/sp_vectors.model.wv.* with mmap=None\n",
      "[INFO] 2020-11-24 16:15:21,050 gensim.utils: loading vectors_ngrams from ../../data/eda/spm/sp_vectors.model.wv.vectors_ngrams.npy with mmap=None\n",
      "[INFO] 2020-11-24 16:15:21,612 gensim.utils: setting ignored attribute vectors_ngrams_norm to None\n",
      "[INFO] 2020-11-24 16:15:21,613 gensim.utils: setting ignored attribute vectors_norm to None\n",
      "[INFO] 2020-11-24 16:15:21,614 gensim.utils: setting ignored attribute vectors_vocab_norm to None\n",
      "[INFO] 2020-11-24 16:15:21,614 gensim.utils: setting ignored attribute buckets_word to None\n",
      "[INFO] 2020-11-24 16:15:21,615 gensim.utils: loading vocabulary recursively from ../../data/eda/spm/sp_vectors.model.vocabulary.* with mmap=None\n",
      "[INFO] 2020-11-24 16:15:21,615 gensim.utils: loading trainables recursively from ../../data/eda/spm/sp_vectors.model.trainables.* with mmap=None\n",
      "[INFO] 2020-11-24 16:15:21,616 gensim.utils: loading vectors_ngrams_lockf from ../../data/eda/spm/sp_vectors.model.trainables.vectors_ngrams_lockf.npy with mmap=None\n",
      "[INFO] 2020-11-24 16:15:22,089 gensim.utils: loaded ../../data/eda/spm/sp_vectors.model\n"
     ]
    }
   ],
   "source": [
    "model = FastText.load(\"../../data/eda/spm/sp_vectors.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
